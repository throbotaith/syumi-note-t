情報理論のちょっとした小旅行を前の章では行った．それでは，$k$アーム確率的バンディットの話に戻ろう．この章では，ホライゾンを$n>0$とし，アクションの数を$k > 1$として考える．この章は2つの構成要素からなっている．
・要素１：正規のバンディットによる固定された方策と，そうではないバンディットとの相対エントロピーの厳密なな計算方法についてである．
・要素２：ミニマックス下界を定式化して証明する．

### バンディット間の相対エントロピー
次の結果は何回も使われる．幾つかの一般化に関する問題は，後の練習問題で訪れるだろう．

#### 補題 15.1 (ダイバージェンスの分解)
 $\nu=\left(P_1, \ldots, P_k\right)$をある$k$アームバンディットと結び付けられた報酬の分布とする．また，$\nu'=\left(P_1', \ldots, P_k'\right)$を別のバンディットの報酬の分布とする．幾つかの方策$\pi$を固定し， $\mathbb{P}_\nu = \mathbb{P}_{\nu\pi}$
および$\mathbb{P}_{\nu^{\prime}}=\mathbb{P}_{\nu^{\prime} \pi}$をそれぞれ，$n$ラウンドの$\pi$の相互作用から誘導される，正規なバンディットモデル(4章でやった最後らへんのやつ)上の確率測度とする．この場合，
$$
\mathrm{D}\left(\mathbb{P}_\nu, \mathbb{P}_{\nu^{\prime}}\right)=\sum_{i=1}^k \mathbb{E}_\nu\left[T_i(n)\right] \mathrm{D}\left(P_i, P_i^{\prime}\right)
$$
が成立する．

##### 証明
good noteにて....


### ミニマックス下界
$\mathcal{E}_{\mathcal{N}}^k(1)$が分散1のガウシアンバンディットであることを思い出してほしい．このバンディットは分散が既知のことから，平均ベクトル$\mu \in \mathbb{R^k}$によってパラメータ化できる．ここで，$\mu \in \mathbb{R^k}$が与えられた場合，$\nu_{\mu}$を，$i$番目のアームの報酬が$\mathcal{N}\left(\mu_i, 1\right)$となるようなガウシアンバンディットとする．

#### 定理 15.2
$k > 1$および，$n \geq k-1$とする．このとき，任意の方策$\pi$について，次の下界をもつような平均ベクトル$\mu \in[0,1]^k$がそんざいする．
$$
R_n\left(\pi, \nu_\mu\right) \geq \frac{1}{27} \sqrt{(k-1) n}
$$

$\nu_\mu \in \mathcal{E}_{\mathcal{N}}^k(1)$より，$\mathcal{E}_{\mathcal{N}}^k(1)$におけるミニマックスリグレットは，$n \geq k-1$と同じように，下界を持つ．

$$
R_n^*\left(\mathcal{E}_{\mathcal{N}}^k(1)\right) \geq \frac{1}{27} \sqrt{(k-1) n}
$$
##### 証明
good noteにて....



図15.1 ミニマックス下界のアイデア![[Screenshot from 2024-04-11 09-28-03.png]]
この図では，1つの環境と方策が与えられるとすると，悪いやつが，方策が少なくとも１つの環境で巨大なリグレットを受け取ってしまうようにするために別の環境を選ぶということ．一番選べれる頻度が低く，報酬もすくない行動を選ぶ感じ？


